Steps for per-pheno input:
- [x] Make `phenos.json` from input files and `PheWAS_code_translation_v1_2.txt`. (2_)
    - Nothing else requires this.
- [x] Make `pheno/<phewas_code>.tsv` by parsing MARKER_ID and subsetting by maf. (0_1)
- [x] Make `sites/cpra.tsv` by intersecting the cpras from all of `pheno/<phewas_code>.tsv` (0_2)
- [x] Make `sites/sites.tsv` from `sites/cpra.tsv` with `rsid` and `nearest_gene`. (1_2-1_7)
    - [x] Handle gene overlaps like 1:879911 (NOC2L,SAMD11)
    - [x] Sort correctly (including multi-allelics)
- [x] Make `augmented_pheno/<phewas_code>.tsv` by extracting `sites/sites.tsv` positions (& [nearest_gene, rsids]) from the raw input files. (3_1)
- [x] Make `main-matrix.tsv` from all `augmented_pheno/<phewas_code>.tsv`. (4_1)
    - This mostly keeps one cpu at 100% usage.
    - We could have calculated mean_maf beforehand, and then we'd just need to concat pval columns.  That could be done recursively -- just divide up the files among the cpus.

- [x] `cpra-to-rsid.marisa_trie`: Trie from chr-pos-ref-alt -> rsid (1_8.1)
- [x] `rsid-to-cpra.marisa_trie`: Trie rsid -> from chr-pos-ref-alt (1_8.2)
- [x] `manhattan/<phewas_code>.json` (3_2)
    - when rsids == '', should I leave it undefined?
    - [/] Mark which variants which are peaks, and specify whether they should appear in the graph or just the StreamTable.
        - Or just mark peaks, and later subset by pval.
        - While variants w/ p<1e-4: m_s_v = min(significant_variants, key=_.pval); m_s_v.showgene=True; significant_variants = [v for v in significant_variants if abs(v.pos-m_s_v.pos) > 100k]
- [x] `qq/<phewas_code>.json` (3_3)

- [ ] Webpage: pheno.html: 1 <-> 4 QQ.
- [x] Webpage: variant.html: StreamTable of [pheno_code, pheno_string, icd9_info, neglog10_pval(desc)]
- [x] Webpage: pheno.html: StreamTable of [cpra, maf, nearest_gene, neglog10_pval(desc)] with checkbox "show only strongest hit for each gene"
- [ ] Webpage: pheno.html: for variants that have the "showgene" attribute (and pval<1e-8?), show their gene above them, but behind the points if possible.
- [ ] LZ - see Andrew's code.


Later:
- Require a parser script for input files, which will be used for `cpra.tsv` and `augmented_pheno/<pheno_code>`.
    - parse_input_file.py should offer a generator function from an input file that returns [cpra, pval, maf].
- Rename 0_1 -> 0_1_get_cpras_from_each_input_file.
    - Or maybe just integrate it into 0_2 to cut down tmp file usage by ~5X.
- Rename 0_2 -> 0_2_get_cpras_to_show.
- Make phenos.csv with [pheno_code, pheno_string, input_file_path].
    - Generated by 0_0 from a glob and regex and `PheWAS_code_translation_v1_2.txt`.
    - Maybe also category?  Should ICD9 info go in it?
- Fill more of `gwas-trait-mapping.csv` and re-Manhattan those phenotypes.
    - use `cat gwas_catalog_v1.0.1-associations_e84_r2016-06-12.tsv | cut -f 35 | tr , "\n" | sed 's_^ __' | sort -u | less`
- Show GWAS Catalog info on variant.html (using rs#)
- Write a Makefile to do all of this?  Snakemake?
- Invert colors (like ctrl-opt-com-8)?
- Keep annoations separate from data, and maybe put data into hdf5 of flat files to save some space.
    - Maybe add row# into annoations (sites.tsv) to index into the matrices.
    - Maybe keep separate row-major and column-major matrices, or just a separate file for each phenotype.


Info:
- 39355320 variants in each input file I checked
- 7878230 variants in `cpra-any.tsv`. (MAF>0.01 in at least one pheno)
- 7878127 variants in any pheno, with sorted alt.
- 7602114 variants in `cpra-all.tsv`. (MAF>0.01 in all phenos) (except 769 350.3 350.6)
- 1448 phenos
- But `cat phenos.json | grep "\": {" | wc -l` finds only 1440.  Which 8 had <20 cases?


Timing:
- 0_1: ~6 hrs (~10 min/pheno) (think)
- 0_2:
    - 21 min (all, 8-at-a-time)
    - 13 min (any, 8-at-a-time)
    - 24 min (any, 4-at-a-time)
    - slower with io.open(fname, buffering=2**16)
    - 30 min (any, 8-at-a-time, sorted alt)
- 1_2: 8 min
- 1_3: 10 sec
- 1_4: 9 min
- 1_5: 40 sec
- 1_6: 30 sec
- 1_7: 20 sec
- 1_8: 1 min
- 2: .
- 3_1: ~6 hrs
- 3_2: ~1 hr (2 min/pheno) (guess)
- 3_3: ~1 hr (2 min/pheno) (guess)
- 4_1: ~5 hr
- 4_2: 1.7 hr
